{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries, modules\n",
    "\n",
    "Sequence; core/generic, specific, modules [a-z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select from extensive list of imports\n",
    "from __future__ import print_function, division\n",
    "import argparse\n",
    "import inspect\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "import torch \n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from mymods.lauthom import *\n",
    "\n",
    "\n",
    "# plot inline\n",
    "%matplotlib inline\n",
    "\n",
    "# set seeds for reproduction\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# interactive mode on\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch (pretrained) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {name: models.__dict__[name] for name in models.__dict__\n",
    "                     if name.islower() \n",
    "                     and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name])}\n",
    "\n",
    "dictify(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data transforms and augmentation before loading\n",
    "\n",
    "Compose augmentation(random), transforms for training and validation/test sets.\n",
    "Set size equal to model \n",
    "Create tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All torchvision pre-trained models expect input images normalized in the same way, \n",
    "# i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), \n",
    "# where H and W are expected to be at least 224. \n",
    "\n",
    "# Generic function to build transforms\n",
    "def transform_composer(img_size=0, val_size=0, **kwargs):\n",
    "    \"\"\"Build composed data transforms.\n",
    "    \n",
    "    :args: e.g.: img_size=224, val_size=256\n",
    "           kwargs: boolean list of transforms in correct order:\n",
    "           resize=True, c_crop=True, r_crop=True, flip=True, rotate=True, \n",
    "           tensor=True, normalize=True\n",
    "    :return: composed transform\"\"\"\n",
    "    \n",
    "    # The images have to be loaded into a range of [0, 1] and then normalized using \n",
    "    MEAN, SD = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "    train_dict = {\n",
    "         'r_crop': transforms.RandomResizedCrop(img_size),\n",
    "         'flip': transforms.RandomHorizontalFlip(),\n",
    "         'rotate': transforms.RandomRotation(5),\n",
    "         'tensor': transforms.ToTensor(),      \n",
    "         'normalize': transforms.Normalize(MEAN, SD)\n",
    "    }\n",
    "    val_dict = {\n",
    "         'resize': transforms.Resize(val_size),\n",
    "         'c_crop': transforms.CenterCrop(img_size),\n",
    "         'tensor': transforms.ToTensor(),      \n",
    "         'normalize': transforms.Normalize(MEAN, SD)\n",
    "    }\n",
    "    \n",
    "    # Select transforms based on kwargs\n",
    "    train_transforms = [train_dict[k] for k, v in kwargs.items() if v and k in train_dict]\n",
    "    val_transforms = [val_dict[k] for k, v in kwargs.items() if v and k in val_dict]\n",
    "    \n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose(train_transforms),\n",
    "        'val': transforms.Compose(val_transforms)\n",
    "        }\n",
    "    return data_transforms  \n",
    "    \n",
    "    \n",
    "# Compose transforms\n",
    "# img_size, val_size = 224, 256\n",
    "cnn_transforms = transform_composer(img_size=224, val_size=256, resize=True, c_crop=True, \n",
    "                                    r_crop=True, flip=True, rotate=True, tensor=True, normalize=True)\n",
    "\n",
    "# Sanity check: list of transforms\n",
    "dictify(cnn_transforms['train'].__dict__)\n",
    "dictify(cnn_transforms['val'].__dict__)\n",
    "\n",
    "# FashionMNIST\n",
    "fmnist_transforms = transform_composer(flip=True, rotate=True, tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_path('_data', 'hymenoptera_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check data directory for subfolders and files\n",
    "data_dir = '../../_data/hymenoptera_data'\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", data_dir]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build loaders\n",
    "M_BATCH = 8\n",
    "WORKERS = 4\n",
    "PHASES = ['train', 'val']\n",
    "TRANSFORMS = cnn_transforms\n",
    "    \n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          TRANSFORMS[x])\n",
    "                                          for x in PHASES}\n",
    "\n",
    "dataloaders = {x: data.DataLoader(image_datasets[x], batch_size=M_BATCH,\n",
    "                                  shuffle=True, num_workers=WORKERS)\n",
    "                                  for x in PHASES}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Sanity check images, class labels\n",
    "dictify(image_datasets['train'].__dict__)\n",
    "dictify(image_datasets['val'].__dict__)\n",
    "print(dataset_sizes)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image viewer function\n",
    "def imshow(inp, title=None, sep=' ', fontsize=24):\n",
    "    \"\"\"Show images of Tensors in Dataloader.\"\"\"\n",
    "    MEAN, SD = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "    inp = inp.numpy().transpose((1, 2, 0)) # convert to np\n",
    "    inp = (SD * inp) + MEAN\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    width = len(title) * 3 | 20\n",
    "    plt.figure(figsize=(width, 5))\n",
    "    plt.imshow(inp)\n",
    "    plt.axis('off')\n",
    "    if title is not None:\n",
    "        plt.title(sep.join(title), fontsize=fontsize)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a batch of training data\n",
    "# Make a grid from batch\n",
    "def show_batch():\n",
    "    inputs, classes = next(iter(dataloaders['train']))\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    imshow(out, ['Label: {}    '.format(class_names[x]) for x in classes], '    ')\n",
    "\n",
    "show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model \n",
    "or \n",
    "Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network Architecture Class\n",
    "# IF NOT PRELOADED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Pytorch pretrained models\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() \n",
    "                     and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name]))\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic function to set/define pretrained model\n",
    "def pre_model(model, pretrained=True, freeze=True):\n",
    "    \"\"\"\"\"\"\n",
    "    model = models.__dict__[model](pretrained=pretrained)\n",
    "    # freeze parameters in backprop\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    num_ftrs = model.fc.in_features    # no. of features in fc layer\n",
    "    model.fc = nn.Linear(num_ftrs, 2)  # change out_features to 2 (binary loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define/set model\n",
    "model_all = pre_model('resnet18', pretrained=True, freeze=False)\n",
    "model_freeze = pre_model('resnet18', pretrained=True, freeze=True)\n",
    "\n",
    "# Sanity check: show model and architecture change\n",
    "print(model_all)\n",
    "print(models.resnet18(pretrained=True).fc)\n",
    "print(model_all.fc)\n",
    "dictify(model_all.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LR = 0.001\n",
    "MOMENTUM = 0.9\n",
    "DECAY_STEP = 7  # epoch steps between LR decay\n",
    "DECAY_LR = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for binary classification\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer functions: optimize ALL parameters vs. final layer only\n",
    "optimizer_all = optim.SGD(model_all.parameters(), \n",
    "                          lr=LR, \n",
    "                          momentum=MOMENTUM)\n",
    "optimizer_freeze = optim.SGD(model_freeze.fc.parameters(), \n",
    "                             lr=LR, \n",
    "                             momentum=MOMENTUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay LR\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_all, \n",
    "                                       step_size=DECAY_STEP, \n",
    "                                       gamma=DECAY_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictify((dataloaders['train'].__dict__))\n",
    "\n",
    "# labels in dataloader\n",
    "[labels.data for (inputs, labels) in dataloaders['train']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging model performance metrics\n",
    "class Log(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    import sys\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.val = 0.0\n",
    "        self.sum = 0.0\n",
    "        self.count = 0\n",
    "        self.avg = 0.0\n",
    "\n",
    "    def __call__(self, val, batch=1):\n",
    "        self.val = val/batch\n",
    "        self.sum += val\n",
    "        self.count += batch\n",
    "        self.avg = self.sum / self.count\n",
    "    \n",
    "    def get_class_name(self):\n",
    "        f = sys._getframe(1)\n",
    "        try:\n",
    "            class_name = f.f_locals['self'].__class__.__name__\n",
    "        except KeyError:\n",
    "            class_name = None\n",
    "        return class_name\n",
    "    \n",
    "    def get(self):\n",
    "        return self.avg\n",
    "        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}: {:.3f}'.format(self.name, self.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for existing model, load and resume\n",
    "def load_model(model, optimizer, num_epochs, resume=True):\n",
    "    \"\"\"Load and resume from existing model.\n",
    "    :return: model path\"\"\"\n",
    "    model_name = os.path.join(data_dir,\n",
    "                              str(model.__class__.__name__)+'_'+\n",
    "                              str(optimizer.__class__.__name__)+'_'+\n",
    "                              str(num_epochs)+'.pk1')\n",
    "    if os.path.exists(model_name) and resume:\n",
    "        model.load_state_dict(torch.load(model_name))\n",
    "    return model_name\n",
    "\n",
    "# Sanity check: path\n",
    "load_model(model_all, optimizer_all, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic train helper functions\n",
    "\n",
    "\n",
    "def b_ward(loss, optimizer, scheduler):\n",
    "    \"\"\"Backpropagate loss.\"\"\"\n",
    "    # TODO implementation of scheduler\n",
    "    # scheduler.step()        # LR decay\n",
    "    optimizer.zero_grad()   # reset gradients\n",
    "    loss.backward()         # backprop loss\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "\n",
    "def f_ward(model, phase, criterion, inputs, labels):\n",
    "    \"\"\"Forward pass.\n",
    "    \n",
    "    http://pytorch.org/docs/master/notes/autograd.html#volatile\n",
    "    :return: loss and accuracy\n",
    "    \n",
    "    :note:\n",
    "    Deprecated? volatile=(phase=='val'),\n",
    "    Volatile is recommended for purely inference mode, when you’re sure you won’t be even calling .backward(). \n",
    "    It’s more efficient than any other autograd setting - it will use the absolute minimal amount of memory to evaluate the model. \n",
    "    volatile also determines that requires_grad is False.\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = Variable(inputs, requires_grad=(phase=='train'))\n",
    "    labels = Variable(labels)\n",
    "    \n",
    "    # Compute loss and predict label(max log-probability)\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    sum_correct = torch.sum(preds==labels.data).item()\n",
    "    \n",
    "    return loss, sum_correct\n",
    "\n",
    "    \n",
    "def train(model, loader, scheduler, criterion, optimizer, phase):\n",
    "    \"\"\"Training, validation for each epoch. Forward, backward props and caching metrics.\n",
    "    \n",
    "    :return: loss and accuracy\"\"\"\n",
    "    model.train(phase=='train')\n",
    "#     cache = {'cum_count': 0, 'cum_loss': 0.0, 'cum_acc': 0.0, \n",
    "#              'avg_loss': 0.0, 'avg_acc': 0.0}\n",
    "    \n",
    "    # FJE initialize logs\n",
    "    batches = Log('Batch id')\n",
    "    batch_time = Log('Duration')\n",
    "    losses = Log('Loss')\n",
    "    corrects = Log('Accuracy')\n",
    "    lap = time.time()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader):\n",
    "        \n",
    "        # forward\n",
    "        loss, sum_correct = f_ward(model, phase, criterion, inputs, labels)\n",
    "        \n",
    "        # backward\n",
    "        if phase == 'train':\n",
    "            b_ward(loss, optimizer, scheduler)\n",
    "            \n",
    "        # stats\n",
    "#         cache['cum_count'] += inputs.size()[0]\n",
    "#         cache['cum_loss'] += loss.item() # FJE data[0]\n",
    "#         cache['cum_acc'] += sum_correct\n",
    "#         cache['avg_loss'] = cache['cum_loss']/cache['cum_count']\n",
    "#         cache['avg_acc'] = cache['cum_acc']/cache['cum_count']\n",
    "\n",
    "        # FJE print batch log\n",
    "        if i % 5 == 0:\n",
    "            print('{:<13}{:>03}/{:<3}{:>13.3f}{:>14.3f}{:>11.3f}sec'.format('Train-batch',\n",
    "                batches.count, len(loader), losses.get(), corrects.get(), batch_time.get()))\n",
    "            \n",
    "        # FJE logging loss, accuracy and elapsed time\n",
    "        batches(i)\n",
    "        losses(loss.item(), inputs.size()[0])\n",
    "        corrects(sum_correct, inputs.size()[0])\n",
    "        batch_time(time.time() - lap)\n",
    "        lap = time.time()\n",
    "            \n",
    "\n",
    "        \n",
    "#         printdb(cache['avg_loss'], losses)\n",
    "#         printdb(cache['avg_acc'], corrects)\n",
    "                \n",
    "    return losses.get(), corrects.get() #cache['avg_loss'], cache['avg_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic function for training and evaluation of validation set\n",
    "def eval_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \"\"\"Running training and validation.\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Load last best model saved\n",
    "    model_name = load_model(model, optimizer, num_epochs, resume=True)\n",
    "    print(model_name)\n",
    "    \n",
    "    best_model = {'model': model_name, 'best_acc': 0.0, 'best_model_wts': model.state_dict()}\n",
    "    \n",
    "    print_header()\n",
    "    \n",
    "    for epoch in np.arange(num_epochs)+1:\n",
    "        #lap = time.time()\n",
    "    \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            lap = time.time()\n",
    "            \n",
    "            loss, acc = train(model, dataloaders[phase], scheduler, criterion, optimizer, phase)\n",
    "                \n",
    "            # update LR decay\n",
    "            if phase == 'val':\n",
    "                scheduler.step(loss)\n",
    "                \n",
    "            # update and save best_model\n",
    "            if (phase=='val') and (acc>best_model['best_acc']):\n",
    "                best_model['best_acc'], best_model['best_model_wts'] = acc, model.state_dict()\n",
    "                torch.save(model.state_dict(), best_model['model'])\n",
    "                \n",
    "            end = time.time()\n",
    "            print_stat(phase, epoch, loss, acc, end-lap)\n",
    "            \n",
    "    finish = time.time()            \n",
    "    print_model_performance(finish-start, best_model)\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model['best_model_wts'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats print helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_format(secs):\n",
    "    \"\"\"Convert seconds to h:mm:ss.\"\"\"\n",
    "    m, s = divmod(secs, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return \"%d:%02d:%02d\" % (h, m, s)\n",
    "\n",
    "\n",
    "def print_header():\n",
    "    \"\"\"Print header.\"\"\"\n",
    "    h_template = \"\"\"\\n{:<14}{:>5}{:>14}{:>14}{:>14}\"\"\"\n",
    "    print(h_template.format('Phase', 'Epoch', 'Loss', 'Accurracy', 'Duration'))\n",
    "\n",
    "       \n",
    "def print_stat(phase, epoch, loss, acc, duration):\n",
    "    \"\"\"Print loss, accuracy and duration at each epoch/phase.\"\"\"\n",
    "    p_template = \"\"\"{:<14}{:>05}{:>14.4f}{:>14.1f}{:>14}\"\"\"\n",
    "    print(p_template.format(phase, epoch, loss, acc*100, time_format(duration)))\n",
    "    \n",
    "        \n",
    "def print_model_performance(duration, best_model):\n",
    "    \"\"\"Print best model performance and total duration.\"\"\"\n",
    "    print('\\nTraining and validation completed in: {:8}\\n'\n",
    "          'Best validation Accuracy: {:2.1f}%\\n'\n",
    "          'Learned model saved: {:16}\\n'.format(\n",
    "           time_format(duration), round(best_model['best_acc']*100), 2), best_model['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "# Train and evaluate validation set\n",
    "model_all = eval_model(model_all, \n",
    "                       criterion, \n",
    "                       optimizer_all, \n",
    "                       exp_lr_scheduler, \n",
    "                       num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance\n",
    "\n",
    "Tune hypermparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "Only learn final layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train weights in final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "model_freeze = eval_model(model_freeze, \n",
    "                          criterion, \n",
    "                          optimizer_freeze, \n",
    "                          exp_lr_scheduler, \n",
    "                          num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# use object to collect data to print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict per batch\n",
    "def pred_batch(model):\n",
    "    \"\"\"Predict labels for one batch\"\"\"\n",
    "    \n",
    "    inputs, labels = next(iter(dataloaders['val']))\n",
    "    v_inputs, v_labels = Variable(inputs), Variable(labels)\n",
    "    \n",
    "    outputs = model(v_inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    \n",
    "    return zip(inputs, preds, labels.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "def show_pred_batch(model, n_batches, n_columns=M_BATCH):\n",
    "    \"\"\"Show from n batches n predictions\"\"\"\n",
    "    \n",
    "    for _ in range(n_batches):\n",
    "        it_batch = list(pred_batch(model))\n",
    "        \n",
    "        title = ['Prediction: {} ({})'.format(class_names[yhat], str(class_names[y]==class_names[yhat]).upper()) \n",
    "                  for _, yhat, y in it_batch][:n_columns]\n",
    "        inputs = ([inp for inp, _, _ in it_batch])[:n_columns]\n",
    "        preds = ([pred for _, pred, _ in it_batch])[:n_columns]\n",
    "        # Make a grid from batch\n",
    "        out = torchvision.utils.make_grid(inputs, padding=0, pad_value=0)\n",
    "        imshow(out, title, ' '*8, 14)\n",
    "\n",
    "    return None\n",
    "\n",
    "# Show predictions\n",
    "show_pred_batch(model_freeze, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a batch of training data\n",
    "# Make a grid from batch\n",
    "def show_batch():\n",
    "    inputs, classes = next(iter(dataloaders['val']))\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    imshow(out, ['Label: {}'.format(class_names[x]) for x in classes], ' '*8)\n",
    "\n",
    "show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "save_model = True\n",
    "if save_model is True:\n",
    "    #saves only params\n",
    "    torch.save(model_ft.state_dict(), 'model_ft.pk1')\n",
    "    torch.save(model_conv.state_dict(), 'model_conv.pk1')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
